block_type: "conformer"
learn_prosody: True

duration_modeling:
  learn_alignment: False
  aligner_temperature: 0.0005

prosody:
  # Du et al., 2021
  learn_mixture: False # This is only supported under supervised duration modeling (learn_alignment: False)
  extractor_kernel_size: 9
  predictor_kernel_size: [9, 5]
  predictor_num_gaussians: 20
  predictor_dropout: 0.2

  # Liu et al., 2021
  learn_implicit: True # This is only tested under supervised duration modeling (learn_alignment: False)
  bottleneck_size_u: 256
  bottleneck_size_p: 4
  ref_enc_filters: [32, 32, 64, 64, 128, 128]
  ref_enc_size: [3, 3]
  ref_enc_strides: [1, 2] # '1' is to keep the sequence length
  ref_enc_pad: [1, 1]
  ref_enc_gru_size: 32
  ref_attention_dropout: 0.
  token_num: 32
  predictor_kernel_size: [9, 5] # [9, 5] for non-parallel predictor / 3 for parallel predictor
  predictor_dropout: 0.5

transformer:
  encoder_layer: 4
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 2
  decoder_hidden: 256
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.2
  decoder_dropout: 0.2

conformer:
  encoder_layer: 4
  encoder_head: 8
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 8
  decoder_hidden: 256
  feed_forward_expansion_factor: 4
  conv_expansion_factor: 2
  conv_kernel_size: 31
  half_step_residual: True
  encoder_dropout: 0.1
  decoder_dropout: 0.1

reformer:
  depth: 6
  encoder_head: 8
  decoder_head: 8

variance_predictor:
  filter_size: 256
  kernel_size: 3
  dropout: 0.5

variance_embedding:
  kernel_size: 9
  pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
  energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
  n_bins: 256

multi_speaker: False

max_seq_len: 1000

vocoder:
  model: "HiFi-GAN" # support 'HiFi-GAN', 'MelGAN'
  speaker: "universal" # support  'LJSpeech', 'universal'
